#### Начнем разворачивать кафку
![](Pasted%20image%2020251226050246.png)
пупупу....
Меняем образ на актуальный, запускаем:
![](Pasted%20image%2020251226050416.png)
Ура, кластер поднялся
![](Pasted%20image%2020251226050448.png)
#### Создадим топик с помощью команды:

```shell
docker run -it --rm --network kafka-kraft-cluster_default confluentinc/cp-kafka:latest kafka-topics \
--create \
--topic test_topic \
--bootstrap-server kafka01:9092,kafka02:9092,kafka03:9092 \
--partitions 8 \
--replication-factor 3 \
--if-not-exists
```

Убеждаемся что все ок:
![](Pasted%20image%2020251226050639.png)
![](Pasted%20image%2020251226050826.png)
Разберемся какой параметр за что отвечает:

| Параметр           | Значение      | Зачем нужен                                                                                   |
| ------------------ | ------------- | --------------------------------------------------------------------------------------------- |
| Partitions         | 8             | Позволяет параллелить запись и чтение. Чем больше партиций, тем выше потенциальный throughput |
| Replication Factor | 3             | Каждая партиция хранится на всех 3 брокерах                                                   |
| Leader             | 1 на партицию | Принимает запись                                                                              |
| Followers          | 2             | Реплицируют данные                                                                            |
Про отказоустойчивость: при Replication Factor = 3 можно потерять одного брокера без потери доступности, а при двух запись станет невозможной.
#### Запускаем нагрузочное тестирование:

```shell
docker run -it --rm --network kafka-kraft-cluster_default confluentinc/cp-kafka /bin/kafka-producer-perf-test --topic test_topic --num-records 1000000 --throughput -1 --producer-props bootstrap.servers=kafka01:9092,kafka02:9092,kafka03:9092 batch.size=16384 acks=1 linger.ms=50 --record-size 1000
```
![](Pasted%20image%2020251226055549.png)
1. RPS 
	- средний - 43750
	- максимальный - 55000
2. Пропускная способность 
	- средняя - 41.72 МБ/сек
	- пиковая - 52.48 МБ/сек
3. Latency
	- средняя - 702 мс
	- максимальная - 2.5 сек
	- P50 - 682 мс
	- P95 - 1.45 сек
	- P99 - 2.25 сек
	- P99.9 - 2.34 сек

Получается половина событий записывается < 682 мс, 95% сообщений < 1.45 сек, для гарантии 99% требуется 2.25. Так получается из-за батчинга и таймаута на соединения, acks=1 означает, что лидер подтверждает запись без ожидания реплик. Такие показатели говорят об отсутствии очередей и равномерной нагрузке.
![](Pasted%20image%2020251226052308.png)
Как видим, записалось на все три брокера.
#### Отказоустойчивость
Запустили питоновский скрипт, убедились, что сообщения полетели:
![](Pasted%20image%2020251226061104.png)
![](Pasted%20image%2020251226061153.png)
Контроллер первый, вырубаем его через docker stop:
![](Pasted%20image%2020251226061416.png)
![](Pasted%20image%2020251226061431.png)
Видим, что первый брокер отвалился, но сообщения все еще отправляются на кафку:
![](Pasted%20image%2020251226061548.png)
Еще раз остановим контроллер, оставим всего одного брокера:
![](Pasted%20image%2020251226061706.png)
![](Pasted%20image%2020251226061748.png)
скрипт начал сыпать таймаутами:
![](Pasted%20image%2020251226061905.png)
KafkaUi работает, но некорректно (ф5 прожимал после остановки второго брокера):
![](Pasted%20image%2020251226062225.png)
Топики не загружаются совсем:
![](Pasted%20image%2020251226062250.png)

Данные больше не пишутся, потому что число живых реплик меньше чем ISR (In-Sync Replicas, набор живых реплик, которые успевают за лидером)
В логах последнего выжившего ошибки о подключении к двум другим брокерам:
![](Pasted%20image%2020251226063418.png)
![](Pasted%20image%2020251226063825.png)
Особенно к последнему лидеру.
Теперь перезапустим первого убитого:
![](Pasted%20image%2020251226064017.png)
Ошибки из скрипта ушли, мы продолжили писать:
![](Pasted%20image%2020251226064140.png)
![](Pasted%20image%2020251226064254.png)
![](Pasted%20image%2020251226064239.png)
Восстановим последнего брокера:
![](Pasted%20image%2020251226064502.png)
Спустя 30 секунд все данные консистентны, ошибок нет, кафка восстановилась без перезапуска
![](Pasted%20image%2020251226064647.png)
![](Pasted%20image%2020251226064658.png)